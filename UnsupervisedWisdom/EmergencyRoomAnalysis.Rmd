---
title: "Emergency Room Falling Injury Analysis"
output: html_notebook
---

#Introduction
This analysis was done by Mike Goldweber, Sept 2023. Submitted to DrivenData.org on Oct 6, 2023. This document shows;
the step by step process of analyzing the emergency room data provided in the Unsupervised Wisdom contest.

The full set of project files can be found at: https://github.com/halciber/Machine-Learning/tree/master/UnsupervisedWisdom.

# Data Ingestion
The data used in this project is the Primary data set. This contains 115,128 rows of data. The data is pulled into two dataframes. One called df_original, and the other is called df_mapped. The df_mapped set is modified by the example code so that it produces human readable data. the df_original set will be modified by the feature engineer to be usable by the modeling done below.



```{r}
#You'll want to adjust your file path for your environment
filepath <- "c:\\_working\\Machine-Learning\\UnsupervisedWisdom\\Data\\primary_data.csv"

df_original <- read.csv(filepath)

#we'll use this variable frequently
rowcount <- nrow(df_mapped)
```

## Setting up the categorical mapping dataframe
The code for the next two blocks was take directly from the Community Code section of the contest website, found at: https://www.drivendata.org/competitions/217/cdc-fall-narratives/community-code/.The purpose of this block is to take the JSON coding information and match it to the numeric values found in primary_data.csv. I've found this version of the dataset to be helpful in understanding the data. For example, "57 - FRACTURE" is more meaningful than the original "57". My intention is to use the df_mapped dataframe primarily with the data exploration and the. df_original, created in the code block above will be used for the modeling work after modification in the Feature Engineer section below.

```{r}
library(jsonlite)

mappingfile <- 'c:\\_working\\Machine-Learning\\UnsupervisedWisdom\\Data\\variable_mapping.json'
mapping <- fromJSON(mappingfile)
names(mapping)

# Convert to data frames so we can use in joins
mapping_tables <- list()
for (col in names(mapping)) {
    mapping_tables[[col]] <- data.frame(
        ind=as.integer(names(mapping[[col]])),  # change to integer types
        values=unlist(mapping[[col]])
    )
}
```

Now that the JSON information has been ingested, we'll map the categories on to the dataframe, which we will call **df_mapped**.
```{r}
library(dplyr)

# Load primary data
df_mapped <- df_primary

# Join and replace encoded column
for (col in names(mapping)) {
    df_mapped <- df_mapped %>%
        left_join(mapping_tables[[col]], by=setNames("ind", col)) %>%
        mutate(!!col := values) %>%
        select(-values)
}


```





# Data Clean Up/ Preliminary Feature Engineer
Let's look at the dataset to get an initial feel for the data quality by running a summary

```{r}
summary(df_original)
```
Usually a concern is missing data scattered randomly thoughtout the set. In this case, the summary shows the data is in good shape. That is there isn't much in the way of missing data. The only NA's we see are in the diagnosis_2 and body_part_2 columns. This isn't a suprise, because the ER patients didn't necessarily suffer secondary injuries. There is a correlation between these two columns, given the identical number of NAs at 71,983. These columns will have to be explored further to determine if it should be used in our modeling.

However, glancing at the data sets directly shows gaps in some of the other columns. For example body_part_2, other_diagnosis and other_diagnosis_2 contain many gaps.

```{r}
#scroll to the right to see the empty columns (example body_part_2, other_diagnosis and other_disagnosis_2).
head(df_mapped)
```


# Data Exploration
This is actually the critical portion of the project, and most of the effort was spent on this work in order to understand the scope of the problem. The results of this exploration affected later portions of the exploration. Please note, the narrative column won't be looked at in the data exploration. The goal is to use ChatGPT to analyze  this data and return helpful results. So, this part of the data is being handled separately.

Let's begin by looking at correlations between the columns.

## Correlation Plot

```{r}
library(corrplot)

#we need to use numerical values for the correlation. So, we'll make a subset of the data.
df_numsubset<- df_original[, c(4:6, 8:9, 13, 15:22)]

#visualization matrix of the data, looking for correlations
corrplot(cor(df_numsubset), type= "upper")

rm(df_numsubset)
```
We see strong correlations between race and hispanic, product_1 and product_2, as well as product_2 and product_3. Honestly, this doesn't seem to be very helpful. At least as this stage. Our focus is on the injuries. There are some connections to age and some of the other factors. Including alcohol. So, we'll have to explore this.

## Age
Let's look at the age category. In particular, let's see if there is a particular age that is hit harder than another age. The block converts it into a table, and the plot shows the frequency of injuries by age.
```{r}
library(ggplot2)


#frequency of injuries by age
data <- df_numsubset[, c('age', 'sex')]
df_agefreq <- as.data.frame(table(data$age))
colnames(df_agefreq)[1] <- "age" 
colnames(df_agefreq)[2] <- "frequency" 
#head(df_agefreq)
ggplot(df_agefreq) + 
    geom_count(mapping = aes(x=age, y=frequency)) + 
    labs(title = "Frequency of Injury By Age", x="Age", y="Count")
```
What is interesting about this plot, it shows that the injury frequency is relatively high (over 3500) until age 88. I am wondering if the fall off is due to some environmental movement, or is the population over 88 shrinking? There is a bit of a plateau for ages 71-80, where each group has over 4000 injuries, except for age 76 with 3993 injuries. 

## Sex (Gender)
Next, let's look at the breakdown of sex (gender) in this dataset.

```{r}
#63% of the injuries are to women

genderlabels <- c("Male", "Female")
gender <- as.vector(df_original[ ,'sex'])
gentable <- as.data.frame(table(gender))

gentable$gender <- mapvalues(gentable$gender, c( "1", "2"), genderlabels)

pie(gentable$Freq, labels = genderlabels, main="Sex Breakdown")

percentoffemales <- (gentable[2, 'Freq']/rowcount*100)
out <- sprintf("Percentage of females in this dataset: %f)", percentoffemales) #percentage of females in this dataset
out

```
This plot visually shows the breakdown of sex in this dataset. We see that at **63.1%**, females represents the majority of cases in this dataset. So, we'll pay particular attention to the factors affecting this part of the population.


```{r, include=FALSE}
#cleanup
rm(gender, gentable, genderlables, out)
```





### Age and Gender
Next, let's look at the split by age and gender.

```{r}
library(ggplot2)
library(sqldf)
library(reshape2)

results <- sqldf('SELECT age, sex, count(sex) AS "frequency"
                        FROM df_mapped
                        GROUP BY age, sex')

# reshape the dataframe into a long format
results <- melt (results, id.vars = c ("sex", "age"))

# plot two lines for different genders
ggplot (results, aes (x = age, y = value, group = sex, color = sex)) +
  geom_line () +
  labs (x = "Age", y = "Injury Frequency", color = "Sex")
```

```{r, include=FALSE}  
rm(results)
```


This chart shows a significant difference by gender across the ages of the patients. First, this plot confirms the previous pie chart plot by showing the female population suffers greater numbers of injuries *across the age spectrum*. As we explore further, we'll have to consider the possibility of using different approaches for helping each gender. Of note, this shows the data set only includes males and females. The other categories are not represented in this dataset.


## Data Exploration by Race and Sex
Next, let's factor in the race of the patients to see if any particular group is affected more than the others. After looking at the upper level data by race, we'll look at the hispanic breakdown at the population.


### Breakdown By Race
We'll start off with a simple pie chart to see.


```{r}

if (system.file(package = "waffle") == "") {
  install.packages("waffle")
}

library(ggplot2)
library(waffle)

rcounts <- as.data.frame(table(df_mapped$race))
colnames(rcounts)[1]<-"race"
colnames(rcounts)[2]<-"frequency"

vec <- numeric()
vecS <- character()

for(i in rcounts$frequency)
{
    x <- i/rowcount
    x <- x*100
    vec <- c(vec, x)
    
    s <- ifelse((x > 7.0), sprintf("%.2f%%", x), "")#display only meaning values on the pie chart
    vecS <- c(vecS, s)
}

rcounts <- cbind(rcounts, new_col = vec)
colnames(rcounts)[3]<-"percent"

rcounts <- cbind(rcounts, new_col = vecS)
colnames(rcounts)[4]<-"labels"

ggplot(rcounts, aes(x = "", y = percent, fill = race)) +
  geom_bar(stat="identity", width=1) +
  geom_text(aes(label = labels), position = position_stack(vjust = 0.5)) +
  scale_fill_manual(values = c("#E59866", "#FCF3CF", "#AF601A", "#AED6F1", "#BD0026", "#27AE60", "#FAD7AD")) + ##E59866
  coord_polar("y", start=0) + 
  labs(title = "Breakdown of the Patient Population by Race",
          #subtitle = "test",
          caption = "34.4% did not state their race, making a racial correlation difficult")
```    

```{r, include=FALSE}  
rm(vec, vecS, x, s, rcounts)
```
This chart is problematic, because of the high percentage of N.S. (not stated). So it maybe difficult to accurately identify a racial component to these injuries. 

### Hispanic


```{r}
if (system.file(package = "waffle") == "") {
  install.packages("waffle")
}

library(ggplot2)
library(waffle)

hcounts <- as.data.frame(table(df_mapped$hispanic))
colnames(hcounts)[1]<-"hispanic"
colnames(hcounts)[2]<-"frequency"

vec <- numeric()
vecS <- character()

for(i in hcounts$frequency)
{
    x <- i/rowcount
    x <- x*100
    vec <- c(vec, x)
    
    s <- sprintf("%.2f%%", x)
    vecS <- c(vecS, s)
}

hcounts <- cbind(hcounts, new_col = vec)
colnames(hcounts)[3]<-"percent"

hcounts <- cbind(hcounts, new_col = vecS)
colnames(hcounts)[4]<-"labels"

ggplot(hcounts, aes(x = "", y = percent, fill = hispanic)) +
  geom_bar(stat="identity", width=3) +
  geom_text(aes(label = labels), position = position_stack(vjust = 0.5)) +
  scale_fill_manual(values = c("#E59866","#27AE60", "#FCF3CF")) +   
  coord_polar("y", start=0) + 
  labs(title = "Breakdown of the Hispanic Population",
          #subtitle = "test",
          caption = "Only 3% of the patients identify as Hispanic")
```
So, the majority of patients are not hispanic, however, we can't conclude not being hispanic makes a person more likey to fall.
```{r, include=FALSE}
#cleanup
rm(vec, vecS, x, s, hcounts)
```


```{r}
if (system.file(package = "moonBook") == "") {
  install.packages("moonBook")
}

if (system.file(package = "webr") == "") {
  install.packages("webr")
}

library(moonBook)
library(ggplot2)
library(webr)
library(dplyr)

rhcounts <- as.data.frame(table(df_mapped$hispanic, df_mapped$race))
colnames(rhcounts)[1]<-"hispanic"
colnames(rhcounts)[2]<-"race"
colnames(rhcounts)[3]<-"frequency"

webr::PieDonut(rhcounts, aes(hispanic, race, count=frequency), 
              r0 = 0.3, #hides the center
               r1 = 0.7,
               #explode = 3,
               #explodeDonut = TRUE,
               pieLabelSize = 3,
               donutLabelSize = 4,
               title = "Hispanic and Racial Breakdown")

```
As with the Hispanic pie chart, and with only 3% of the injured set being hispanic, I'm not convinced that hispanic=yes correlates to a fall. Further, no one racial group stands out Certainly, part of the Unk/Not Stated group is probably hispanic, but we don't know for certain. Further obfuscating this part of the hispanic set is the N.S part of the race data, which represents 76% of the Unknown hispanic group. 


We'll continue to look at race, but I don't believe there is anything to be gained from including the hispanic column in our model.



```{r, ignore=TRUE}
rm(rhcounts)
```



## Diagnosis
Next is a look at the diagnosis column. We'll start off by looking for the most heavily diagnosed injuries.

```{r}
#grouping the diagnosis column, looking for the most frequent injury

##frequency of each diagnosis
dcounts <-df_mapped[, c('diagnosis')]

df_diagnosisfreq <- as.data.frame(table(dcounts))
colnames(df_diagnosisfreq)[1] <- "diagnosis_code" 
colnames(df_diagnosisfreq)[2] <- "frequency" 

#sort the data in descending order
df_diagnosisfreqSorted <- df_diagnosisfreq[order(-df_diagnosisfreq$frequency),]
head(df_diagnosisfreqSorted)

#cleanup
rm(dcounts, df_diagnosisfreq)
```
From this sorting, we know that fractures, internal injuries, contusions abj, and lacertations make up the majority of the 26 listed injuries by a significant amount.

```{r}
#based on the frequency of this plot, we can see that the first 4 items represent the majority of the diagnosis
#lets look at the percentage of the cases

highest4diagnosis <- sum(df_diagnosisfreqSorted$frequency[1:4]) # This equals 99,868
percentoftop4diagnosis <- highest4diagnosis/rowcount    #115128=total injuries 86.7%
print(sprintf("Percentage of the top 4 injuries is: %f%%, or %i total reported injuries.", percentoftop4diagnosis*100, highest4diagnosis))


library(ggplot2)
library(waffle)


rm(vec, vecs)

vec <- numeric()
vecS <- character()
vecColor <- character()

n <- nrow(df_diagnosisfreqSorted)

for(i in 1:n)
{
    row <- df_diagnosisfreqSorted[i, ]
    
    code <- as.character(row$diagnosis_code)
    freq <- as.integer(row$frequency)
    
    print(c(code, freq))
    
    perc <- (freq/rowcount)*100
    
    vec <- c(vec, perc) #add value to a vector
    sDiag <- ifelse((perc > 10.0), sprintf("%s", code), "")#display only meaning values on the pie chart
    vecS <- c(vecS, sDiag)
    
    sColor <- ifelse((i < 5), "#AA0000", "#0000AA")
    vecColor <- c(vecColor, sColor)                     
}#end of apply


df_diagnosisfreqSorted <- cbind(df_diagnosisfreqSorted, new_col = vec)
colnames(df_diagnosisfreqSorted)[3]<-"percent"

df_diagnosisfreqSorted <- cbind(df_diagnosisfreqSorted, new_col = vecS)
colnames(df_diagnosisfreqSorted)[4]<-"labels"

df_diagnosisfreqSorted <- cbind(df_diagnosisfreqSorted, new_col = vecColor)
colnames(df_diagnosisfreqSorted)[5]<-"colors"

ggplot(df_diagnosisfreqSorted, aes(x = "", y = frequency, fill = diagnosis_code)) +
  geom_bar(stat="identity", width=1) +
  geom_text(aes(label = labels), position = position_stack(vjust = 0.5)) +
  #scale_fill_manual(values = df_diagnosisfreqSorted$colors) +
  coord_polar("y", start=0)

```
Seeing the majority (86%) of the dataset is diagnosed with these 4 injuries (fractures, internal injuries, contusions abj, and lacertations), our focus will be on how age, race and location play a part with these injuries. 

### Injuried Diagnosed Over Time
Before that, let's see if when the injuries took place plays a role. However, we will focus on the top 4 diagnosed injuries.
```{r}
if (system.file(package = "sqldf") == "") {
  install.packages("sqldf")
}
library(sqldf)
 
injuriesbydate <- sqldf('SELECT treatment_date, diagnosis, count(*) as frequency
                         FROM df_mapped
                         WHERE (diagnosis = "53 - CONTUSIONS, ABR." or diagnosis = "57 - FRACTURE" or diagnosis = "59 - LACERATION" or diagnosis = "62 - INTERNAL INJURY")
                         GROUP BY treatment_date, diagnosis
                         ORDER BY treatment_date
                        ')
#, diagnosis, count(diagnosis)
#
#GROUP BY diagnosis, GROUP BY treatment_date
#ORDER BY treatment_date
head(injuriesbydate)

injuriesbydate$diagnosis <- as.factor(injuriesbydate$diagnosis)

ggplot (injuriesbydate, aes (x = treatment_date, y = frequency, group = diagnosis, color = diagnosis)) +
  geom_line () +
  labs (x = "Treatment Date", y = "Injury Frequency", color = "Diagnosis")

  

```
This was meant to show 4 nice lines, but there is a wide date range in this plot. While seeing a specific date is not possible, we can see a spike in the injuries in the last third of of the time period. Looking further into this would be worthwhile.

```{r}
m53 <- sqldf('SELECT MEDIAN(frequency) as median
             FROM injuriesbydate
             WHERE (diagnosis = "53 - CONTUSIONS, ABR.")
             ')

m57 <- sqldf('SELECT MEDIAN(frequency) as median
             FROM injuriesbydate
             WHERE (diagnosis = "57 - FRACTURE")
             ')

m59 <- sqldf('SELECT MEDIAN(frequency) as median
             FROM injuriesbydate
             WHERE (diagnosis = "59 - LACERATION")
             ')

m62 <- sqldf('SELECT MEDIAN(frequency) as median
             FROM injuriesbydate
             WHERE (diagnosis = "62 - INTERNAL INJURY")
             ')
print(
    sprintf("The median values for each injury over time are 53 = %.2f, 57 =  %.2f, 59 = %.2f, 62 = %.2f", m53, m57, m59, m62)
    )

m53 <- sqldf('SELECT MEDIAN(frequency) as median
             FROM injuriesbydate
             WHERE (diagnosis = "53 - CONTUSIONS, ABR.") AND (treatment_date > \'2022-01-01\')
             ')

m57 <- sqldf('SELECT MEDIAN(frequency) as median
             FROM injuriesbydate
             WHERE (diagnosis = "57 - FRACTURE") AND (treatment_date > \'2022-01-01\')
             ')

m59 <- sqldf('SELECT MEDIAN(frequency) as median
             FROM injuriesbydate
             WHERE (diagnosis = "59 - LACERATION") AND (treatment_date > \'2022-01-01\')
             ')

m62 <- sqldf('SELECT MEDIAN(frequency) as median
             FROM injuriesbydate
             WHERE (diagnosis = "62 - INTERNAL INJURY") AND (treatment_date > \'2022-01-01\')
             ')
print(
    sprintf("The median values for each injury in 2022 are 53 = %.2f, 57 =  %.2f, 59 = %.2f, 62 = %.2f", m53, m57, m59, m62)
    )

```
These results confirm the visualization. The question is, why is there a spike in the injuries? Could it be the result of COVID lock downs ending, and people leaving their homes? Or is there something else? Time permitting, it might be interesting to see what factors are different for the last third of the time range.

```{r, ignore=TRUE}
#cleanup
rm(vec, vecS, vecColor, df_diagnosisfreqSorted)
rm(m53, m57, m59, m62, injuriesbydate)
```

### Injuries by Racial Group
This visualization plots the injuries by racial group and gender. Outside of people reporting as white, no one group stood out at disproportional numbers, but breaking this down by injury could expose a problem.

```{r}

injuryracegender <- sqldf('SELECT diagnosis, sex, race, count(*) as frequency
                         FROM df_mapped
                         WHERE (diagnosis = "53 - CONTUSIONS, ABR." or diagnosis = "57 - FRACTURE" or diagnosis = "59 - LACERATION" or diagnosis = "62 - INTERNAL INJURY")
                         GROUP BY diagnosis, sex, race
                        ')


ggplot(injuryracegender) + 
    geom_point(mapping = aes(x=diagnosis, y=frequency, color=race, alpha=race, shape=sex)) + 
    labs(title = "Frequency of Injury By Diagnosis, Gender, & race <100", x="Diagnosis", y="Count") +
    scale_y_continuous(limits = c(0, 99))

ggplot(injuryracegender) + 
    geom_point(mapping = aes(x=diagnosis, y=frequency, color=race, alpha=race, shape=sex)) + 
    labs(title = "Frequency of Injury By Diagnosis, Gender, & race <500", x="Diagnosis", y="Count") +
    scale_y_continuous(limits = c(100, 499))

ggplot(injuryracegender) + 
    geom_point(mapping = aes(x=diagnosis, y=frequency, color=race, alpha=race, shape=sex)) + 
    labs(title = "Frequency of Injury By Diagnosis, Gender, & race <1000", x="Diagnosis", y="Count") +
    scale_y_continuous(limits = c(500, 999))

ggplot(injuryracegender) + 
    geom_point(mapping = aes(x=diagnosis, y=frequency, color=race, alpha=race, shape=sex)) + 
    labs(title = "Frequency of Injury By Diagnosis, Gender, & race <3500", x="Diagnosis", y="Count") +
    scale_y_continuous(limits = c(1000, 3499))

ggplot(injuryracegender) + 
    geom_point(mapping = aes(x=diagnosis, y=frequency, color=race, alpha=race, shape=sex)) + 
    labs(title = "Frequency of Injury By Diagnosis, Gender, & race >=3500", x="Diagnosis", y="Count") +
    scale_y_continuous(limits = c(3500, 7500))
```
Based on what these charts are showing us, I don't believe minority groups are being disproportionately affected. Whites and N.S. appear to be the greatest number of patients. So, for the scope of this project, I don't see race being a factor.

### Fire Involvement, Alcohol, and Drug Use
Related to the injuries are the cases of burns and alcohol having an effect on the falling injuries. Let's take a look to see how the patient population in this dataset has been affected by them.We know from the diagnosis frequencies, that burn injuries 

#### Fire Involvement
```{r}
##frequency of the burn diagnosis
burncounts <- sqldf('SELECT diagnosis, count(diagnosis) AS "frequency"
                        FROM df_mapped
                        WHERE (diagnosis = "47 - BURN, NOT SPEC." or diagnosis = "49 - BURN, CHEMICAL" or diagnosis = "48 - BURN, SCALD" or diagnosis = "51 - BURNS, THERMAL")
                        GROUP BY diagnosis
                        ORDER BY frequency DESC')

head(burncounts)


##frequency of fire_involvement
fcounts <-df_mapped[, c('fire_involvement')]

df_firefreq <- as.data.frame(table(fcounts))
colnames(df_firefreq)[1] <- "fire_involvement" 
colnames(df_firefreq)[2] <- "frequency" 

#sort the data in descending order
df_FireIsFreqSorted <- df_firefreq[order(-df_firefreq$frequency),]
head(df_FireIsFreqSorted)

#cleanup
rm(burncounts, fcounts, df_firefreq, df_FireIsFreqSorted)
```
From these numbers, we see there is very few burn injuries. Eightyone total, or 0.7% of the total dataset. For this project, we won't explore burn injuries or fire involvement further because this is such a small part of the population.

#### Alcohol
Unlike the burns and fire involvement, there isn't a set of injuries that specifically connects with alcohol usage. So, if we see a large number of patients that reported alcohol usage, it will be interesting to see which diagnosis were tied to it.

```{r}
##frequency of the burn diagnosis
alcoholcounts <- sqldf('SELECT alcohol, count(alcohol) AS "frequency"
                        FROM df_mapped
                        GROUP BY alcohol
                        ORDER BY frequency DESC')

head(alcoholcounts)

yestotal <- alcoholcounts[2,2]

percent <- yestotal/rowcount*100
print(sprintf("Percentage of cases where alcohol was related to the falling injury: %.2f%%.", percent))
#cleanup
rm(alcoholcounts, yestotal, percent)
```
The number of alcohol related cases is 2588, or 2.25% of the patients in the dataset. For this project, we won't explore alcohol further because this represents a small part of the population.

#### Drug Use
Let's check to see if drug use played a big impact on the falling injuries.

```{r}
library(sqldf)

##frequency of the burn diagnosis
drugcounts <- sqldf('SELECT drug, count(drug) AS "frequency"
                        FROM df_mapped
                        GROUP BY drug
                        ORDER BY frequency DESC')

head(drugcounts)

yestotal <- drugcounts[2,2]

percent <- yestotal/rowcount*100
print(sprintf("Percentage of cases where alcohol was related to the falling injury: %.2f%%.", percent))
#cleanup
rm(drugcounts, yestotal, percent)
```
Drug use covers 4% of the injuries, or 4645 cases. This does represent a small amount of the patient population.

## Locations Where Patients Reported Getting Hurt
I want to take a quick look at where people are getting hurt. This could impact how we look for correlations later on.

```{r}

locationresults <- sqldf('SELECT location, count(location) AS "frequency"
                        FROM df_mapped
                        WHERE (diagnosis = "53 - CONTUSIONS, ABR." or diagnosis = "57 - FRACTURE" or diagnosis = "59 - LACERATION" or diagnosis = "62 - INTERNAL INJURY")
                        GROUP BY location')

pie(locationresults$frequency, labels = locationresults$location, main="Location Breakdown")

#Add home, public, and unknown, the top 3 locations for injuries
locationsum <- locationresults[2, 2] + locationresults[5, 2] + locationresults[9, 2]
print(sprintf("The total of home, public, and unknown is %i. This represents %.2f%% of the total dataset.", locationsum, locationsum/rowcount))
#percentoffemales <- (gentable[2, 'Freq']/rowcount*100)
#ut <- sprintf("Percentage of females in this dataset: %f)", percentoffemales) #percentage of females in this dataset
#out
```
This pie chart isn't the prettiest, but it does clearly show that Home is the primary location where injuries take place. This is followed up by Public and Unknown. Unknown is a frustrating result for this portion of the data, because it isn't clear how to mitigate problems at this location.


## Diagnosis, Race, and Gender
Let's look to see if there is any correlation between the injuries, race, and gender, with the focus being on the top 4 injuries identified above.

```{r}
if (system.file(package = "sqldf") == "") {
  install.packages("sqldf")
}

library(sqldf)
library(dplyr)
library(plyr)
library(ggplot2)


#frequency of each diagnosis by gender
results <- sqldf('SELECT diagnosis, sex, count(*) AS "frequency"
                        FROM df_mapped
                        WHERE (diagnosis = "53 - CONTUSIONS, ABR." or diagnosis = "57 - FRACTURE" or diagnosis = "59 - LACERATION" or diagnosis = "62 - INTERNAL INJURY")
                        GROUP BY diagnosis, sex
                        ORDER BY diagnosis, sex, frequency DESC')


#plot them
ggplot(results) + 
    geom_count(mapping = aes(x=diagnosis, y=frequency, color=sex)) + 
    labs(title = "Frequency of Injury By Diagnosis & Gender", x="Diagnosis", y="Count")
```
 From this plot, we can see that women are severely diagnosed with "57 - Fractures" and "63 - Internal Injury"; however, women suffer from all of these top diagnosis more than men. **So special attention** has to be paid for addressing the factors affecting women.
 
## Diagnosis, Sex (Gender), and Location 
So far, we've seen individual breakdowns of the data, but let's start mixing up the columns in the hopes of exposing a culprete to the problem.

```{r}
locationresults <- sqldf('SELECT location, diagnosis, sex, count(sex) AS "frequency"
                        FROM df_mapped
                        WHERE (diagnosis = "53 - CONTUSIONS, ABR." or diagnosis = "57 - FRACTURE" or diagnosis = "59 - LACERATION" or diagnosis = "62 - INTERNAL INJURY")
                        GROUP BY location, diagnosis, sex')
sum(locationresults$frequency) #results = 99868
    #<-    df_firefreq[order(-df_firefreq$frequency),]
sorted <- locationresults[order(-locationresults$frequency),]

head(sorted)

rm(locationresults, sorted)

```
This result is interesting because we see that fractures and internal injuries affect women by a significant amount **at home**.


# Location, Diagnosis, Body Part
Now that we've identified females are being disproportional hurt at home, which body_part is affected the most? 

I'm focused on the women, however, let's continue to look at men in the query.
```{r}
locationresults <- sqldf('SELECT location, diagnosis, body_part, sex, count(sex) AS "frequency"
                        FROM df_mapped
                        WHERE (diagnosis = "53 - CONTUSIONS, ABR." or diagnosis = "57 - FRACTURE" or diagnosis = "59 - LACERATION" or diagnosis = "62 - INTERNAL INJURY")
                        GROUP BY location, diagnosis, body_part,  sex')
sum(locationresults$frequency) #results = 99868
    #<-    df_firefreq[order(-df_firefreq$frequency),]
sorted <- locationresults[order(-locationresults$frequency),]

head(sorted)

```
These results are helpful. Previously we saw fractures at the most serious problem. However, when we factor in the body_part we see the internal injuries to the head at home and in the public location is the most serious problem

```{r, ignore=TRUE}
rm(locationresults, sorted)
```

Let's look at this same data with just the women.
```{r}

locationresults <- sqldf('SELECT location, diagnosis, body_part, sex, count(sex) AS "frequency"
                        FROM df_mapped
                        WHERE (diagnosis = "53 - CONTUSIONS, ABR." or diagnosis = "57 - FRACTURE" or diagnosis = "59 - LACERATION" or diagnosis = "62 - INTERNAL INJURY") AND
                                (sex = "FEMALE")
                        GROUP BY location, diagnosis, body_part,  sex')
sum(locationresults$frequency) #results = 99868
    #<-    df_firefreq[order(-df_firefreq$frequency),]
sorted <- locationresults[order(-locationresults$frequency),]

head(sorted)

```
From this table, we see that when the diagnosis is an internal injury, the head is the body part injuried the most. Home is the most likely place for the injuries, followed by the public or unknown locations. Next most frequent injury is the upper or lower trunk experiencing fractures.

Let do a similar query for the males to see how they are affected.
```{r}

locationresults <- sqldf('SELECT location, diagnosis, body_part, sex, count(sex) AS "frequency"
                        FROM df_mapped
                        WHERE (diagnosis = "53 - CONTUSIONS, ABR." or diagnosis = "57 - FRACTURE" or diagnosis = "59 - LACERATION" or diagnosis = "62 - INTERNAL INJURY") AND
                                (sex = "MALE")
                        GROUP BY location, diagnosis, body_part,  sex')
sum(locationresults$frequency) #results = 99868
    #<-    df_firefreq[order(-df_firefreq$frequency),]
sorted <- locationresults[order(-locationresults$frequency),]

head(sorted)

```
The results for men are very similar in that internal injuries to the head are hit the male population with the greatest frequency. Also, like the females, we see that males experience the fractures to the lower and upper trunk most frequently (after the head injuries), and the major of these injuries are at home.

## Products
A quick look at the product numbers.

```{r}
library(sqldf)

productresults <- sqldf('SELECT product_1, count(product_1) AS "frequency"
                        FROM df_mapped
                        WHERE (diagnosis = "53 - CONTUSIONS, ABR." or diagnosis = "57 - FRACTURE" or diagnosis = "59 - LACERATION" or diagnosis = "62 - INTERNAL INJURY")
                        GROUP BY product_1')

productresults <- productresults[order(-productresults$frequency),]

#get the results that equate to at least 1% of the patients (ie 1000+)
productresults <- sqldf('SELECT * 
                        FROM productresults
                        WHERE frequency > 1000
                        ')



head(productresults)

```
The variable productresults will be used below

## Connections to Products?
Next, let's see if there is a tie to the products.

```{r}
library(sqldf)

locationresults <- sqldf('SELECT location, diagnosis, body_part, product_1,  sex, count(sex) AS "frequency"
                        FROM df_mapped
                        WHERE (diagnosis = "53 - CONTUSIONS, ABR." or diagnosis = "57 - FRACTURE" or diagnosis = "59 - LACERATION" or diagnosis = "62 - INTERNAL INJURY")
                        GROUP BY location, diagnosis, body_part, product_1,  sex')

    #<-    df_firefreq[order(-df_firefreq$frequency),]
sorted <- locationresults[order(-locationresults$frequency),]

head(sorted)

```
This query shows the majority of products are tied to floors or flooring materials. Does this mean the patient just fell on the floor leading to the internal injuries and fractures? Also of note home, internal injury, and heads are the most likely to be the combination for our patients. Let's look at the same data with just the floors.

```{r}

locationresults <- sqldf('SELECT location, diagnosis, body_part, product_1,  count(product_1) AS "frequency"
                        FROM df_mapped
                        WHERE (diagnosis = "53 - CONTUSIONS, ABR." or diagnosis = "57 - FRACTURE" or diagnosis = "59 - LACERATION" or diagnosis = "62 - INTERNAL INJURY")
                                AND (product_1 = "1807 - FLOORS OR FLOORING MATERIALS")
                        GROUP BY location, diagnosis, body_part, product_1')
sorted <- locationresults[order(-locationresults$frequency),]
head(sorted)

sum <- sum(locationresults$frequency)
percent <- sum/rowcount * 100

print(   sprintf("The total frequency of the floor/ flooring materials injuries is %i, or %.2f%%.", sum, percent ))

```
As we combine the various data columns to our data exploration, we are seeing distinct groupings of the factors that make up this dataset.


## Tieing Together the Data Exploration.
As previously observed, females at home, suffer internal injuries to their heads when landing on the floors. Let's look at the revised dataset when we look at the most frequently sustain injuries.

```{r}
if (system.file(package = "circlepacketR") == "") {
  install.packages("circlepacketR")
}

library(sqldf)

#
locationresults <- sqldf('select sex, location, diagnosis, body_part, frequency
                        from(
                            SELECT sex, location, diagnosis, body_part, count(*) AS "frequency"
                            FROM df_mapped
                            WHERE (diagnosis = "53 - CONTUSIONS, ABR." or diagnosis = "57 - FRACTURE" or diagnosis = "59 - LACERATION" or diagnosis = "62 - INTERNAL INJURY")
                                  
                            GROUP BY sex, location, diagnosis, body_part
                            ORDER BY sex, location, diagnosis, body_part
                        ) as t
                        WHERE frequency > 500
                        ORDER BY frequency DESC
                        ')




```



## Body Part 2, Products 2, and Product 3
I'm reluctant to delve too deeply into these columns. First, these 3 columns are mostly blank, so where there is data in these columns, it seems to be a secondary result of the body_part and product_1. In other words, if we come up with a way to prevent injury to body_part with product_1, then we can prevent problems with body_part_2 and product_2 and product_3.


# Addition Feature Engineering
This part of the project we will modify the dataset in order to allow the unsupervised model to run efficiently. The next few blocks of code will walk through this process step-by-step.

## Removing extraneous Rows
Based on what we've learned through the data exploration, I believe we can focus on the top 4 diagnosed injuries: fractures, internal injuries, contusions, and lacerations. These 4 diagnoses comprise 86% of the dataset. Next, is the location data. The top 3 represent the vast majority of the cases. Finally, I took the top 14 product_1 items. This is somewhat arbitraty, but unlike the other columns, there isn't a small subset that stands out. So, I opted to take any product where there was at least ~1% of the dataset.

```{r}
#select the top 4 injuries

library(sqldf)
df_modelingdata <- sqldf('SELECT *
                          FROM df_mapped
                          WHERE (diagnosis = "53 - CONTUSIONS, ABR." or diagnosis = "57 - FRACTURE" or diagnosis = "59 - LACERATION" or diagnosis = "62 - INTERNAL INJURY")
                        ')


#select the top 3 locations
df_modelingdata <- sqldf('SELECT *
                          FROM df_modelingdata
                          WHERE (location = "HOME" or location = "PUBLIC" or location = "UNK")
                        ')


#select the top 14 products
df_modelingdata <- sqldf('SELECT *
                          FROM df_modelingdata
                          WHERE (product_1 = "1807 - FLOORS OR FLOORING MATERIALS" 
                                or product_1 = "4076 - BEDS OR BEDFRAMES, OTHER OR NOT SPECIFIED" 
                                or product_1 = "1842 - STAIRS OR STEPS" 
                                or product_1 = "4074 - CHAIRS, OTHER OR NOT SPECIFIED" 
                                or product_1 = "611 - BATHTUBS OR SHOWERS" 
                                or product_1 = "649 - TOILETS" 
                                or product_1 = "4057 - TABLES (EXCL.  BABY CHANGING TABLES, BILLIARD OR POOL TABLES" 
                                or product_1 = "676 - RUGS OR CARPETS, NOT SPECIFIED" 
                                or product_1 = "1884 - CEILINGS AND WALLS (INTERIOR PART OF COMPLETED STRUCTURE)" 
                                or product_1 = "1615 - FOOTWEAR" 
                                or product_1 = "4078 - LADDERS, OTHER OR NOT SPECIFIED" 
                                or product_1 = "1817 - PORCHES, BALCONIES, OPEN-SIDE FLOORS OR FLOOR OPENINGS" 
                                or product_1 = "1893 - DOORS, OTHER OR NOT SPECIFIED"
                                or product_1 = "3299 - EXERCISE (ACTIVITY OR APPAREL, W/O EQUIP)")
                        ')

#verify the smaller dataset.
modelrowct <- nrow(df_modelingdata)

print(sprintf("The new row count is %i. The percentage of the row count in the modified dataset vs the original set: %.2f%%.", modelrowct, modelrowct/rowcount))

head(df_modelingdata)

```
The new row count matches what was shown in the data exploration. There must have been a lot of overlap with the eliminated injury and location row, because the total comes down to 85%. The first filtering (of the injuries) brought the total down to 86% of the original, so removing these locations didn't change much.

## Removing extraneous Columns

Next, the data exploration revealed that race, other race, hispanic, fire, alcohol, and drug use did not appear to be major factors in the fall. So these columns will be eliminated.

The focus of this project is to prevent falling injuries. The disposition column represents the end of the incident, which doesn't help us prevent the fall. So, this column will be eliminated.

Columns other race, other diagnosis, diagnosis 2, other diagnosis 2, body part 2, product 2, and product 3 contain too many empty values. So, these columns will be eliminated as well.
```{r}
library(dplyr)
df_modelingdata <- select(df_modelingdata, -c(race, hispanic, fire_involvement, alcohol, drug, disposition))

df_modelingdata <- select(df_modelingdata, -c(other_race, other_diagnosis, diagnosis_2, other_diagnosis_2, body_part_2, product_2, product_3))

head(df_modelingdata)
```

## Creating a dataset for use with the LLM.
I want a parallel dataset to use with ChatGPT. So, at this step, I'm going to copy df_modelingdata before additional modifications.

```{r}
#copy df_modelingdata
df_llm <- df_modelingdata
```



## Creating Binary Columns
Using numeric value for the modeling is more efficient. In this step, we'll convert the character columns into n number of binary columns.

The fastDummies library comes from "Kaplan, J. & Schlegel, B. (2023). fastDummies: Fast Creation of Dummy (Binary) Columns and Rows from Categorical Variables. Version 1.7.1. URL: https://github.com/jacobkap/fastDummies, https://jacobkap.github.io/fastDummies/."

```{r}
if (system.file(package = "fastDummies") == "") {
  install.packages("fastDummies")
}

library(fastDummies)

#each df will need the case number as a unique ID to merge with the df_modelingdata
casenumber <- df_modelingdata$cpsc_case_number


#create a df for each of the columns to make into binary columns
sex <- df_modelingdata$sex
df1 <- fastDummies::dummy_cols(as.data.frame(sex))
#add the case number, remove the sex column
df1$cpsc_case_number <- casenumber
df1 <- select(df1, -c(sex))

diagnosis <- df_modelingdata$diagnosis
df2 <- fastDummies::dummy_cols(as.data.frame(diagnosis))
df2$cpsc_case_number <- casenumber
df2 <- select(df2, -c(diagnosis))

bodypart <- df_modelingdata$body_part
df3 <- fastDummies::dummy_cols(as.data.frame(bodypart))
df3$cpsc_case_number <- casenumber
df3 <- select(df3, -c(bodypart))

location <- df_modelingdata$location
df4 <- fastDummies::dummy_cols(as.data.frame(location))
df4$cpsc_case_number <- casenumber
df4 <- select(df4, -c(location))

product <- df_modelingdata$product_1
df5 <- fastDummies::dummy_cols(as.data.frame(product))
df5$cpsc_case_number <- casenumber
df5 <- select(df5, -c(product))


#merge each of the small columns into df_modelingdata
df_modelingdata <- merge(df_modelingdata, df1, by = "cpsc_case_number")
df_modelingdata <- merge(df_modelingdata, df2, by = "cpsc_case_number")
df_modelingdata <- merge(df_modelingdata, df3, by = "cpsc_case_number")
df_modelingdata <- merge(df_modelingdata, df4, by = "cpsc_case_number")
df_modelingdata <- merge(df_modelingdata, df5, by = "cpsc_case_number")

rm(sex, diagnosis, bodypart, location, product)
rm(df1, df2, df3, df4, df5)

#now that these columns are now binary, it is time to remove the originals
df_modelingdata <- select(df_modelingdata, -c(sex, diagnosis, body_part, location, product_1))


```

I don't believe the case number will help the modeling, so I'll remove this column from df_modelingdata. For the modeling, the narrative column isn't not helpful.

```{r}
#df_modelingdata <- select(df_modelingdata, -c(cpsc_case_number, narrative))
df_modelingdata <- select(df_modelingdata, -c(treatment_date))

summary(df_modelingdata)
```

# Data Modeling with Hiearchical Model
For this model, I was initially thinking of using a hierarchical clustering model, but I believe my data exploration exposed a hierarchy, so I'm going to look at k-mean-clustering model to look at the data from a different perspective. Its quick and easy to do, but might reveal something interesting.

```{r}
if (system.file(package = "factoextra") == "") {
  install.packages("factoextra")
}
if (system.file(package = "cluster") == "") {
  install.packages("cluster")
}

library(factoextra)
library(cluster)

clusters <- 4
randomsets <- 25

model <- kmeans(df_modelingdata, centers = clusters, nstart = randomsets)

```

# Using ChatGPT for Analysis of the Narrative Data

```{r}

```

